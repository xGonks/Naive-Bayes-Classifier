---
title: "Modeling"
author: "Camila"
format:
   html:
     toc: true
     html-math-method: katex
     embed-resources: true
     self-contained-math: true
     df-print: kable
editor: visual
---

# Sparse Matrix

```{r}
library(tidyverse)
library(tidytext)
library(Matrix)


df = read_delim(
  "../data/data_pages.csv",
  delim = "#$%#$%",
  trim_ws = TRUE
)


df = df %>%
  filter(!is.na(title), !is.na(description)) %>%
  mutate(doc_id = paste0(row_number(), "_", title))  

```

```{r}

tokens = df %>%
  select(doc_id, category, description) %>%
  unnest_tokens(word, description)


data("stop_words")  


tokens = tokens %>%
  anti_join(stop_words, by = "word")

```

```{r}
contar_palabras = tokens %>%
  count(doc_id, word, sort = TRUE)

```

```{r}
sparse_matrix = contar_palabras %>%
  cast_sparse(doc_id, word, n)


top_words = colSums(sparse_matrix) %>% sort(decreasing = TRUE) %>% head(3000) %>% names()
sparse_matrix = sparse_matrix[, top_words]


dim(sparse_matrix)
sparse_matrix[1:5, 1:5]

```

```{r}

df_matrix = as.data.frame(as.matrix(sparse_matrix))

```

```{r}
categories <- df %>%
  distinct(doc_id, category) %>%
  arrange(match(doc_id, rownames(sparse_matrix))) %>%
  pull(category)
```

```{r}

df_matrix$category = categories
```

# Modelado

### Extraer datos

Ultimas columnas de la matriz para serciorarnos que si se agregó categoría

```{r}

df_matrix[1:10, (ncol(df_matrix)-4):ncol(df_matrix)]
       
```

### Limpiar datos

cambiamos el nombre para facil referencia

```{r}
stories = df_matrix
head(stories)
```

quitamos nans

```{r}
stories = stories %>%
  filter(!is.na(category))
```

## Modelo Naive Bayes

#### Dividir matriz

```{r}
library(tidymodels)
```

Ponemos una semilla para replicabilidad.

```{r}
set.seed(123)
```

Adaptamos el split a ambas variables

```{r}
story_split= initial_split(stories, prop = 0.7)
```

```{r}
story_train = training(story_split)
story_test = testing(story_split)
```

```{r}
y_test = factor(story_test[["category"]]) #para debuggear
```

```{r}
#install.packages("e1071")
```

### Modelo e1071

```{r}
library(e1071)
```

```{r}
NB_cl1 = naiveBayes(category ~ . , data = story_train)
```

```{r}
y_pred1 = predict(NB_cl1, newdata = story_test)
```

#### Matriz confusión

```{r}
library(caret)
```

```{r}
y_pred1 = factor(y_pred1)
y_true = factor(story_test[["category"]])
y_pred1 = factor(y_pred1, levels = levels(y_true)) #que tenga en cuenta que existen todas las categorías a pesar de si no las categoriza como tal
```

```{r}
cm = confusionMatrix(y_pred1, y_true, mode = "everything")
cm
```

```{r}
cm$overall["Accuracy"]

```
Para resumir esta información se creó una función para sacar los estadísticos globales
```{r}
# Para hacer esta sección se hizo uso de ChatGPT para optimizar el código propuesto. ChatGPT (GPT-5 Mini). (2025). R function get_caret_report for summarizing confusion matrix metrics [Computer software]. OpenAI.
get_caret_report = function(cm) { 
  accuracy = unname(cm$overall["Accuracy"])
  byclass  = cm$byClass

  # dataframe
  if (is.matrix(byclass)) {
    per_class_df = as.data.frame(byclass)
  } else {
    per_class_df = as.data.frame(t(byclass), stringsAsFactors = FALSE)
    if (!is.null(cm$positive)) rownames(per_class_df) = cm$positive
  }

  cols = colnames(per_class_df)
  find_col = function(patterns) {
    idx = grep(paste(patterns, collapse = "|"), cols, ignore.case = TRUE)
    if (length(idx)) cols[idx[1]] else NA_character_
  }
  prec_col = find_col(c("precision", "pos pred", "ppv"))
  rec_col  = find_col(c("recall", "sensitivity"))
  f1_col   = find_col("f1")

  tab = as.matrix(cm$table)
  tp = diag(tab)
  pred_pos = rowSums(tab)  # PP
  act_pos  = colSums(tab)  #AP

  # Per-class precision/recall/f1
  precision_i = if (!is.na(prec_col)) per_class_df[[prec_col]] else tp / pred_pos
  recall_i    = if (!is.na(rec_col))  per_class_df[[rec_col]]  else tp / act_pos
  f1_i        = if (!is.na(f1_col))   per_class_df[[f1_col]]   else
                 ifelse((precision_i + recall_i) == 0, 0,
                        2 * precision_i * recall_i / (precision_i + recall_i))

  per_class_metrics = data.frame(
    class     = rownames(per_class_df),
    precision = precision_i,
    recall    = recall_i,
    f1        = f1_i,
    support   = act_pos,
    stringsAsFactors = FALSE
  )

  # Macro averages (mean of per-class) and micro averages (global counts)
  macro_precision = mean(per_class_metrics$precision, na.rm = TRUE)
  macro_recall    = mean(per_class_metrics$recall,    na.rm = TRUE)
  macro_f1        = mean(per_class_metrics$f1,        na.rm = TRUE)

  micro_precision = sum(tp) / sum(pred_pos)
  micro_recall    = sum(tp) / sum(act_pos)
  micro_f1 = if ((micro_precision + micro_recall) == 0) 0 else
              2 * micro_precision * micro_recall / (micro_precision + micro_recall)

  summary_df = data.frame(
    Accuracy      = accuracy,
    MacroPrecision= macro_precision,
    MacroRecall   = macro_recall,
    MacroF1       = macro_f1,
    MicroPrecision= micro_precision,
    MicroRecall   = micro_recall,
    MicroF1       = micro_f1,
    row.names = NULL,
    stringsAsFactors = FALSE
  )

  list(summary = summary_df, per_class = per_class_metrics)
}

```

```{r}
res = get_caret_report(cm)
res$summary       # macro/micro + accuracy
res$per_class     # precision/recall/F1/support por clase

```

### Naive Bayes método 2

```{r}
#install.packages("naivebayes")
```

```{r}
library(naivebayes)
```

```{r}
NB_cl2 = naive_bayes(category ~ . , data = story_train)

```

naive_bayes necesita que el test set no tenga el target

```{r}
library(dplyr)
```

```{r}
story_test = story_test %>% dplyr::select(-category)
```

```{r}
y_pred2 = predict(NB_cl2, story_test)
```

#### Debug

```{r}
#DEBUG
dim(story_train)
dim(story_test)
```

```{r}
setdiff(names(story_train), names(story_test))
setdiff(names(story_test), names(story_train))

```

#### Confusion Matrix

```{r}
cm2 = confusionMatrix(y_pred2, y_true, mode = "everything")
cm2
```

```{r}
cm2$overall["Accuracy"]
```

```{r}
res2 = get_caret_report(cm2)
res2$summary       # macro/micro + accuracy
res2$per_class 
```

## Simplificar categorías

```{r}
stories_bin = stories |>
  mutate(
    binary_cat = case_when(
      category == "Haunted Places" ~ "Haunted Places",
      TRUE ~ "Other"   
    )
  )
```

```{r}
stories_bin = stories_bin |>
  select(-category)
```

```{r}
storybin_split= initial_split(stories_bin, prop = 0.7)
```

```{r}
storybin_train = training(storybin_split)
storybin_test = testing(storybin_split)
```

### Clasificación e1071

```{r}
NB_cl3 = naiveBayes(binary_cat ~ . , data = storybin_train)
```

```{r}
y_pred3 = predict(NB_cl3, newdata = storybin_test)
```

```{r}
y_pred3 = factor(y_pred3)
y_trueBIN = factor(storybin_test[["binary_cat"]])
y_pred3 = factor(y_pred3, levels = levels(y_trueBIN)) #que tenga en cuenta que existen todas las categorías a pesar de si no las categoriza como tal
```

#### Confusion Matrix

```{r}
cm3 = confusionMatrix(y_pred3, y_trueBIN, positive = "Haunted Places", mode = "everything")
cm3
```

```{r}
res3 = get_caret_report(cm3)
res3$summary       # macro/micro + accuracy
res3$per_class
```

##### Debug

```{r}
table(storybin_train$binary_cat)
table(storybin_test$binary_cat)
table(y_pred3)
```

```{r}
#y_pred3
```

```{r}
y_trainBIN = factor(storybin_train[["binary_cat"]])
```

### Clasificación 2

```{r}
NB_cl4 = naive_bayes(binary_cat ~ . , data = storybin_train)

```

```{r}
storybin_test = storybin_test %>% dplyr::select(-binary_cat)
```

```{r}
y_pred4 = predict(NB_cl4, storybin_test)
```

#### Confusion matrix

```{r}
cm4 = confusionMatrix(y_pred4, y_trueBIN,positive = "Haunted Places", mode = "everything")
cm4
```

```{r}
res4 = get_caret_report(cm4)
res4$summary       # macro/micro + accuracy
res4$per_class
```

## Distribución Poisson

```{r}
NB_pois = naive_bayes(binary_cat ~ ., storybin_train, usepoisson = TRUE)
```

```{r}
y_predP = predict(NB_pois, storybin_test)
```

### Confusion Matrix

```{r}
cmP = confusionMatrix(y_predP, y_trueBIN, mode = "everything")
cmP
```

## Laplace smoothening

```{r}
NB_poisLAP = naive_bayes(binary_cat ~ ., storybin_train, usepoisson = TRUE, laplace = 1)
```

```{r}
y_predPLAP = predict(NB_poisLAP, storybin_test)
```

### Confusion Matrix

```{r}
cmPLAP = confusionMatrix(y_predPLAP, y_trueBIN, mode = "everything")
cmPLAP
```

## Selección de hiperparámetros

dividir target y predictors

> Éste código es una adaptación de un proyecto con el Profesor Omar

```{r}
# Rango de lambda a evaluar
laplace_vals = seq(0.1, 5, by = 0.5)
set.seed(456)
```

```{r}
acc = c()
folds = createFolds(storybin_train$binary_cat, k = 5, returnTrain = FALSE)

```

```{r}
for (lap in laplace_vals) {
  acc_cv = c()
  
  for (fold in folds) {
    train_data = storybin_train[-fold, ]
    test_data  = storybin_train[fold, ]
    
    # Modelo con  bayes
    model_nb = naive_bayes(binary_cat ~ ., data = train_data,
                           usepoisson = TRUE, laplace = lap)
    
    y_pred = predict(model_nb, test_data %>% select(-binary_cat))
    y_true = test_data$binary_cat
    
    acc_cv = c(acc_cv, mean(y_pred == y_true))
  }
  
  acc = c(acc, mean(acc_cv))
}
```

```{r}
# Mejor Laplace
opt_index = which.max(acc)
opt_hyperparameter = laplace_vals[opt_index]

cat("Laplace óptimo:", opt_hyperparameter, "\n")
```

```{r}
# Gráfica
plot(laplace_vals, acc, type = "b", pch = 19,
     xlab = "Laplace", ylab = "Accuracy",
     main = "Validación cruzada para Naive Bayes")
abline(v = opt_hyperparameter, col = "red", lty = 2)
```
### Usar mejor hyperparámetro

```{r}
NB_poisLAPBEST = naive_bayes(binary_cat ~ ., storybin_train, usepoisson = TRUE, laplace = 1)
```

```{r}
y_predPLAPBEST = predict(NB_poisLAPBEST, storybin_test)
```

### Confusion Matrix

```{r}
cmPLAPBEST = confusionMatrix(y_predPLAPBEST, y_trueBIN, mode = "everything")
cmPLAPBEST
```

## Resumen

```{r}
results_list = list(
  "NaiveBayes_e1071"        = cm,
  "NaiveBayes_naivebayes"   = cm2,
  "Binary_e1071"            = cm3,
  "Binary_naivebayes"       = cm4,
  "Binary_Poisson"          = cmP,
  "Binary_Poisson_Laplace"  = cmPLAP,
  "Binary_BestLaplace"      = cmPLAPBEST
)

summary_all = purrr::map_dfr(
  results_list,
  ~ get_caret_report(.x)$summary,
  .id = "Model"
)

summary_all

```
